{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WEEK 2**\n",
    "\n",
    "- EDA\n",
    "- Validation\n",
    "- Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis(EDA)\n",
    "\n",
    "### 概要\n",
    "\n",
    "1. EDA とは何か？なぜするのか？\n",
    "2. 探索するもの\n",
    "3. 探索と可視化のツール\n",
    "4. データセットクリーニング\n",
    "5. Kaggle コンペにおける EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDAとは何か？なぜするのか？\n",
    "\n",
    "- EDAとは\n",
    "    - データをよく観察し、データをより良く理解すること\n",
    "- EDAをする理由は\n",
    "    - 強い特徴量を生み出し、正確なモデルを構築するため\n",
    "    - データに関する直感を身につけるため\n",
    "    - 新しい効果的な特徴量生成のための仮説を生み出すため\n",
    "    - より良いスコアのためのインサイトを見つけるため\n",
    "    \n",
    "- 複雑なモデルは上位解法でよく見られ、重要ではあるが、一方で彼らは注意深くEDAを行っている。\n",
    "    - モデリングに時間を割くよりも EDA は重要なプロセスである\n",
    "    \n",
    "- コンペはまず EDA から始めるのが良い。\n",
    "    \n",
    "- EDA において可視化が主要な手段の一つである。\n",
    "    - 可視化によってパターンを一目で分かることができる\n",
    "    \n",
    "- [あるコンペ](https://www.kaggle.com/c/dunnhumbychallenge)では、モデリングなしにデータの観察のみで優勝した例がある\n",
    "    - プロモーションを使用するかどうかを予測するコンペ\n",
    "    - プロモーションが送られた累計と使われた累計の列があったので、ユーザーごとに累計をソートして差分を取ると分類機を使用せずとも80％程度の accuracy を出すことができる。\n",
    "        - 当然にこれはデータリークと言えるが、コンペにおいては通常をこれを利用しても良いことになっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データへの直感を身につける\n",
    "\n",
    "- ドメイン知識の取得\n",
    "    - 問題をより深く理解するのに役立つ\n",
    "- データが直感的かどうかを確認する\n",
    "    - ドメイン知識と一致するかどうかを確認する\n",
    "- どのようにデータが生成されたかを理解する\n",
    "    - 適切なバリデーションセットを構築するために必須であるため\n",
    "\n",
    "#### ドメイン知識の取得\n",
    "\n",
    "- コンペには様々な領域のものがあり、しばしばドメイン知識を持っていないコンペに遭遇することがある\n",
    "    - ドメインに対して深く知ることはないが、通常はどんな目的か・どんなデータを持っているか・どのように人々がベースラインを構築しようとしているかを知ることは重要である。\n",
    "    - Google / Wikipedia を使ってデータの種類を理解することがまず第一歩となる\n",
    "    \n",
    "- データのドメインの理解・列名の理解\n",
    "- データの理解後は、データが直感と一致しているかを確認する（ImpはClickより必ず大きいかとか、年齢が100歳以上なのは珍しいとか）\n",
    "    - 年齢が336とかなら、タイポとして33歳か36歳に手動で訂正するのが通常良いが、念の為データ説明を読み直しておく\n",
    "- 一方で、Imp が0なのに Click が3の場合などは通常のエラーであることがある\n",
    "    - スクリプトから送られたデータなどには付きもののエラーでランダムではないことが多いので、これは特徴量として用いるのが良い\n",
    "        - 'is_incorecct' などの列を作るなどして\n",
    "\n",
    "- データがどのように生成されたかを知ることも重要\n",
    "    - データベースからサンプリングされた場合、少数クラスがオーバーサンプリングされて抽出されている可能性がある\n",
    "- データがどのように生成されたかが分かれば、適切なバリデーションセットを作ることができる。\n",
    "- 学習データとテストデータが異なるアルゴリズムで生成されている場合、通常以下のような特徴が見られることが多い\n",
    "    - CVとLBの連動しない\n",
    "    - 各特徴量の分布が異なる\n",
    "    - 各データセットの期間（日付等）の範囲が異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Material for Building Intution about the Data\n",
    "\n",
    "- https://hdinwtxpwdelvatxpgqiri.coursera-apps.org/notebooks/readonly/reading_materials/EDA_video2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匿名データを探索する\n",
    "\n",
    "- 匿名データとは？\n",
    "    - なぜホストはデータを匿名化するのか\n",
    "- 匿名データに対して何ができるか？\n",
    "    - 特徴量の真の意味を推測し、decode してみる\n",
    "    - どのような前処理が必要になるかを知るために、特徴量のデータ型を推測してみる\n",
    "    \n",
    "#### 匿名データとは\n",
    "\n",
    "- 機械学習モデルを構築したいけど、データそのものを公表したくないときにデータ匿名化を行うことがある\n",
    "    - テキストデータがハッシュ関数を通して暗号化する\n",
    "    - テーブルデータでの列名をダミー化する\n",
    "- テーブルデータの列匿名化に対して\n",
    "    - 個別の特徴量に対して\n",
    "        - 列の真の意味を推測する\n",
    "        - 列のデータ型を推測する\n",
    "    - 特徴量の関係に対して\n",
    "        - 特徴量ペアの関連を見つける\n",
    "        - 特徴量のグループを見つける\n",
    "        \n",
    "- [個別の特徴量に対してのアプローチの例](https://hdinwtxpwdelvatxpgqiri.coursera-apps.org/notebooks/readonly/reading_materials/EDA_video3_screencast.ipynb)\n",
    "    - Baseline Model(RF)を構築\n",
    "    - RF の Feature Importance を見て、x8 が重要度が高そうなので探索する\n",
    "        - 平均と分散の確認（ここでは正規分布であることが分かった）\n",
    "        - そのため、元の分布に戻したくなる（scale back）\n",
    "    - value_counts() で繰り返し現れる値を確認\n",
    "        - 出現する数値に偏りがありそうなことがわかった\n",
    "        - 例えば、ユニークな値のみ取り出し、それをソートして、差分を取る\n",
    "            - 多くの差分が同じ値になった(0.043)\n",
    "            - 差分の元の正確な値が分からなくても、例えばそれを1.0と想定してみる(差分を0.043で割る)\n",
    "    - 元の値をそれで割ってみる\n",
    "        - 小数点以下で同じような数値(1.02468)が並ぶので、これを引いてやる\n",
    "        - (train.x8 - 1.02468) / 0.043 として、これを丸め込むと良い感じの整数が出てくる\n",
    "    - スケールバックしたら、再びその値の value_counts() を見てみる\n",
    "        - 最小値に -1968 があったので、西暦っぽいという仮説が成り立つ（ユーザーがテキストボックスに適当に数値を入れた？）\n",
    "        - 1968 を足すと誕生年っぽい感じになる\n",
    "        - このスケールバックした特徴量を用いて、年齢グループなどの新しい特徴量を生成できうる\n",
    "        - （実際にコンペが終了した後、ホストがこの列は誕生年だということを発表した）\n",
    "        \n",
    "#### データ型を推定する\n",
    "\n",
    "- 目視で見ていく\n",
    "- あるいは以下の関数を用いる\n",
    "    - `df.dtypes`\n",
    "    - `df.info()`\n",
    "    - `x.value_counts()`\n",
    "    - `x.isnull()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "データから興味深いものを見つけるのに万能な方法はない。そのため、EDA はある種のアートであり、可視化はそれを実現するためにツールである。\n",
    "可視化は以下の目的のために行う。\n",
    "\n",
    "- 個別の特徴量の探索\n",
    "    - ヒストグラム\n",
    "    - プロット\n",
    "    - 統計量\n",
    "- 特徴量の関係性の探索\n",
    "    - 散布図\n",
    "    - 相関図\n",
    "    - プロット（インデックスと特徴量の統計量の比較）\n",
    "    \n",
    "\n",
    "#### 個別の特徴量の探索\n",
    "\n",
    "**Histogram**\n",
    "\n",
    "`plt.hist(x)`\n",
    "\n",
    "- 特徴量を bins で区切って、各々の bins にいくつの点が含まれるかを示すグラフ\n",
    "    - bins の区切り方にとって誤解を生むことがあるので、bins の区切り方はいくつか試してみると良い。\n",
    "        - ヒストグラムはデータを集計するので、値の詳細を見ることができないので注意が必要。\n",
    "        - ある一つのプロットのみで結論をだすことは誤った結論を導くことになりうる。\n",
    "        - 仮説を立てたら、複数のプロットを使ってそれを実証することが重要である。\n",
    "    - ヒストグラムは大きなピークを持つことがある\n",
    "        - これはホストが欠損値を平均や適当な値で埋めた形跡である可能性が高く、値は元々欠損値だったと推測される。\n",
    "        - この場合、以下のような方法でこの情報を用いることができる。\n",
    "            - 値を再び NaN に置き換えて、欠損値を上手に処理する XGBoost などを使用する\n",
    "            - 平均値ではなく、-999などの値で埋める\n",
    "            - 欠損値かどうかを示す新しい特徴量を追加する（線形モデルで特に有効）\n",
    "            \n",
    "**Plot (index vs. value)**\n",
    "\n",
    "`plt.plot(x, '.')`\n",
    "\n",
    "- X軸に行のインデックス、Y軸に列の値を取るプロット\n",
    "    - 線ではなく、点でプロットした方が、独立した点で見れるので便利である。\n",
    "    - 水平方向に線があることが見られるので、特徴量の中で値が多く繰り返し出現しているが分かる。\n",
    "    - 垂直方向にはパターンが見られないので、データが適切にシャッフルされていることが分かる。\n",
    "\n",
    "`plt.scatter(range(len(x)), x, c=y)`\n",
    "\n",
    "- ラベルごとに色付けすることもできる\n",
    "\n",
    "**特徴量の統計量**\n",
    "\n",
    "```\n",
    "df.describe()  \n",
    "x.mean()  \n",
    "x.var()  \n",
    "```\n",
    "\n",
    "**ユニークな値のカウント**\n",
    "\n",
    "```\n",
    "x.value_counts()  \n",
    "x.isnull()  \n",
    "```\n",
    "\n",
    "\n",
    "#### 特徴量の関係性の探索\n",
    "\n",
    "複数の特徴量のペアの関係を見ることも有効である（特徴量のグループ化を目指す）\n",
    "\n",
    "**散布図**\n",
    "\n",
    "`plt.scatterplot(x1, x2)`\n",
    "\n",
    "- 分類問題の場合、正解ラベルのよって点を色付けするのが便利である。\n",
    "- 回帰問題の場合、ヒートマップ色（グラデーション）で色付けするか、目的変数に比例した点のサイズで表現するのが便利である。\n",
    "\n",
    "- 学習データとテストデータの2特徴量で散布図を作成した時に分布が大きくハズレている場合、コードがバグってるとか、オーバーフィットした特徴量であるとかなどで、よく考える必要がある。\n",
    "\n",
    "- 散布図で X1 と X2 にある関係を見出したら、それを新たな特徴量として用いるのが良い。\n",
    "    - ツリーベースモデルの場合ならば、X1 と X2 の差分や比率を特徴量とすることが考えられる。\n",
    "    \n",
    "- 特徴量の数が少なかったら、 `pd.scatter_matrix(df)` を使うといっぺんに全ての特徴量間の散布図を表示できるので便利。\n",
    "\n",
    "**相関図**\n",
    "\n",
    "`df.corr()`, `plt.matshow( ... )`\n",
    "\n",
    "- 特徴量間の「距離」を計測できる\n",
    "- 特徴量間の独自の距離を計算したいときは、plt.matshow() で独自関数を渡して「距離」を可視化できる\n",
    "- K-meansクラスタリングのようなクラスタリング手法も用いることができる。これにより、特徴量をグループ化することができる。\n",
    "\n",
    "**特徴量の統計量を比較する**\n",
    "\n",
    "`df.mean().plot(style=',')`\n",
    "\n",
    "- 各特徴量の統計量（平均値）を計算して、X軸に特徴量、Y軸に特徴量の統計量を取ると、統計量をグループ化する手がかりになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データクリーニング・その他チェック事項\n",
    "\n",
    "- データクリーニング\n",
    "    - 定常の特徴量\n",
    "    - 重複の特徴量\n",
    "- その他チェック事項\n",
    "    - 重複行\n",
    "    - データセットがシャッフルされているかを確認\n",
    "    \n",
    "#### データクリーニング\n",
    "\n",
    "- すべて一定の特徴量を見つける\n",
    "    - `traintest.nunique(axis=1) == 1` で True のものは列の値がすべて同一なので不要な列である\n",
    "    - `train.nunique(axis=1) == 1` で True の場合も、一般的にはその列は取り除くべきである。\n",
    "        - 特に線形モデルの場合は、書く特徴量に重みを与えるためモデルが不安定になる可能性が高い\n",
    "        - ただし、その列のテストデータのみに現れる値が重要かどうかを判断して慎重に扱う必要がある。\n",
    "        \n",
    "- 重複した特徴量を見つける\n",
    "    - 学習スピードを下げるだけので不要である\n",
    "        - `traintest.T.drop_duplicates()` で取り除くことができる\n",
    "    - また、カテゴリカル変数で違うレベルで同じ値が振られている場合は問題になりうるので、Identical にする必要がある\n",
    "        - `for f in categorical_feats: traintest[f] = traintest[f].facotrize()`\n",
    "        - 'traintest.T.drop_duplicates()`\n",
    "            \n",
    "### その他チェック事項\n",
    "\n",
    "- 重複行\n",
    "    - 同じ特徴量を持った行が同じ正解ラベルを持っているかどうかを確認する\n",
    "        - 同じ特徴量を持った行が異なる正解ラベルを持っている場合、そのコンペはガチャ的なものになるか、あるいはその重複行が単なるミスかもしれない。\n",
    "        - また、学習データとテストデータの間に共通の行があるかを確認すべきである。時々、これによってデータ生成のプロセスが示唆されることがある。その理由を考えることも重要である。\n",
    "        \n",
    "- データセットが適切にシャッフルされているかを確認する\n",
    "    - データセットが適切にシャッフルされていない場合、データリークを見つけることができる可能性がある。\n",
    "    - 特徴量あるいはTarget ValueをY軸に、行のインデックスをX軸に取ることで見つけることができうる。\n",
    "        - Rolling-mean を時に使用することもある。\n",
    "        - Rolling-mean は全体の平均の付近を行き来することを期待するが、そうならないときには何かしらの情報が隠れていることを見つけることができる。\n",
    "        \n",
    "- あらゆる側面から可視化を行うことで、Magic Features を見つけられるようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Materials and Links\n",
    "\n",
    "#### Visualization tools\n",
    "- [Seaborn](https://seaborn.pydata.org/)\n",
    "- [Plotly](https://plot.ly/python/)\n",
    "- [Bokeh](https://github.com/bokeh/bokeh)\n",
    "- [ggplot](http://ggplot.yhathq.com/)\n",
    "- [Graph visualization with NetworkX](https://networkx.github.io/)\n",
    "\n",
    "#### Others\n",
    "- [Biclustering algorithms for sorting corrplots](https://scikit-learn.org/stable/auto_examples/bicluster/plot_spectral_biclustering.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
